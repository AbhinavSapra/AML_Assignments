{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6blhHR4vxmId"
      },
      "outputs": [],
      "source": [
        "# We import all the necessary packages\n",
        "import os\n",
        "import re\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "from textblob import TextBlob\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "# import Pickle\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path =\"/content/drive/MyDrive/\"\n",
        "os.chdir(path)\n",
        "data = pd.read_csv(f\"{path}/emails.csv\")"
      ],
      "metadata": {
        "id": "RbNuNsPa0rFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns\n"
      ],
      "metadata": {
        "id": "Pna5sxqeInYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['text'].head()"
      ],
      "metadata": {
        "id": "hbuuGd4fKDAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['spam'].head()"
      ],
      "metadata": {
        "id": "C5WKCnXtKImJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "id": "fY0SBo83KP6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-Processing"
      ],
      "metadata": {
        "id": "9bsx1b3qKnnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n"
      ],
      "metadata": {
        "id": "9M19b1aKNWtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def tokenize(text):\n",
        "  words = word_tokenize(text.lower())\n",
        "  return words\n",
        "\n",
        "def pre_process(text):\n",
        "  words = tokenize(text)\n",
        "  words = [word for word in words if word.isalpha() and word not in stopwords.words('english')]\n",
        "  return(' '.join(words))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FRgms2K7KXXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['processed_text'] = data['text'].apply(pre_process)\n",
        "for i in range(3):  # Adjust the range based on the number of examples you want to print\n",
        "    print(\"Original:\", data['text'][i])\n",
        "    print(\"Preprocessed:\", data['processed_text'][i])\n",
        "    print()"
      ],
      "metadata": {
        "id": "wrgFErbaPsrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "messages = data['processed_text']\n",
        "labels = data[\"spam\"]\n",
        "data['length'] = data['text'].map(lambda text: len(text))\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(messages, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        ""
      ],
      "metadata": {
        "id": "1APrPTHQnXuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.DataFrame()\n",
        "train_df[\"text\"] = X_train\n",
        "train_df[\"spam\"] = y_train\n",
        "print(\"TRAIN DATA\")\n",
        "print(train_df, \"\\n\\n\\n\")\n",
        "\n",
        "val_df = pd.DataFrame()\n",
        "val_df[\"text\"] = X_val\n",
        "val_df[\"spam\"] = y_val\n",
        "print(\"VALIDATION DATA\")\n",
        "print(val_df, \"\\n\\n\\n\")\n",
        "\n",
        "test_df = pd.DataFrame()\n",
        "test_df[\"text\"] = X_test\n",
        "test_df[\"spam\"] = y_test\n",
        "print(\"TEST DATA\")\n",
        "print(test_df)\n",
        "\n",
        "train_df.to_csv(\"train.csv\", index=False)\n",
        "val_df.to_csv(\"validation.csv\", index=False)\n",
        "test_df.to_csv(\"test.csv\", index=False)"
      ],
      "metadata": {
        "id": "5BM6uRZuneOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"train.csv\")\n",
        "val = pd.read_csv(\"validation.csv\")\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "\n",
        "X_train, y_train = train[\"text\"], train[\"spam\"]\n",
        "X_val, y_val = val[\"text\"], val[\"spam\"]\n",
        "X_test, y_test = test[\"text\"], test[\"spam\"]"
      ],
      "metadata": {
        "id": "cV3kQSo-pHIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "QZ72WAPTglVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bow_transformer = CountVectorizer().fit(train['text'])"
      ],
      "metadata": {
        "id": "-GgUBHqmgBEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emails_bow = bow_transformer.transform(train['text'])"
      ],
      "metadata": {
        "id": "Hr16HLVwsokj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_transformer = TfidfTransformer().fit(emails_bow)"
      ],
      "metadata": {
        "id": "-WzlrAX_swSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL:1 Naive Bayes Classifier"
      ],
      "metadata": {
        "id": "mE3K4ecJBS7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Build and train the model\n",
        "model = Pipeline([('bow',CountVectorizer()),('tfidf', TfidfTransformer()),('classifier', MultinomialNB())])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZHCbb7XOf4tK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%time model_nb=model.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "W83H8lL7vZ38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set\n",
        "predictions = model_nb.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Display classification report\n",
        "print(classification_report(y_test, predictions))"
      ],
      "metadata": {
        "id": "NOi16VWsvSc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL 2: Support Vector Machine"
      ],
      "metadata": {
        "id": "Tue0p2w0BbEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pipeline_sv = Pipeline([\n",
        "    ('bow', CountVectorizer()),  # strings to token integer counts\n",
        "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
        "    ('classifier', SVC()),  # train on TF-IDF vectors w/ SVM classifier\n",
        "])"
      ],
      "metadata": {
        "id": "6q-cHeLLtOEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%time model_sv = pipeline_sv.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "nT-RSBWRtSkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(model_sv.score(X_train, y_train))\n",
        "print(model_sv.score(X_val, y_val))"
      ],
      "metadata": {
        "id": "7YExtOBGtVR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "predictions = model_sv.predict(X_test)\n",
        "print (confusion_matrix(y_test, predictions))\n",
        "print (classification_report(y_test, predictions))"
      ],
      "metadata": {
        "id": "5_p-uPxUtX-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL 3: Random Forest Classifier"
      ],
      "metadata": {
        "id": "Y6BQWpVGBiwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "pipeline_rf = Pipeline([\n",
        "    ('bow', CountVectorizer()),  # strings to token integer counts\n",
        "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
        "    ('classifier', RandomForestClassifier()),  # train on TF-IDF vectors w/ SVM classifier\n",
        "])"
      ],
      "metadata": {
        "id": "vzuz8mtN47dS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%time model_rf = pipeline_rf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "GtMsfD4k6Aom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_rf.score(X_train, y_train))\n",
        "print(model_rf.score(X_val, y_val))"
      ],
      "metadata": {
        "id": "SVj5qkjq6G1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model_rf.predict(X_test)\n",
        "print (confusion_matrix(y_test, predictions))\n",
        "print (classification_report(y_test, predictions))"
      ],
      "metadata": {
        "id": "M3hcQwhz6cWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see the SVM gives the best accuracy amongst the three classifiers."
      ],
      "metadata": {
        "id": "_ShESX_IBqX8"
      }
    }
  ]
}