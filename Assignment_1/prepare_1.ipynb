{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6blhHR4vxmId"
      },
      "outputs": [],
      "source": [
        "# We import all the necessary packages\n",
        "import os\n",
        "import re\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "from textblob import TextBlob\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "# import Pickle\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path =\"/content/drive/MyDrive/\"\n",
        "os.chdir(path)\n",
        "data = pd.read_csv(f\"{path}/emails.csv\")"
      ],
      "metadata": {
        "id": "RbNuNsPa0rFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns\n"
      ],
      "metadata": {
        "id": "Pna5sxqeInYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['text'].head()"
      ],
      "metadata": {
        "id": "hbuuGd4fKDAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['spam'].head()"
      ],
      "metadata": {
        "id": "C5WKCnXtKImJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "id": "fY0SBo83KP6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-Processing"
      ],
      "metadata": {
        "id": "9bsx1b3qKnnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n"
      ],
      "metadata": {
        "id": "9M19b1aKNWtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def tokenize(text):\n",
        "  words = word_tokenize(text.lower())\n",
        "  return words\n",
        "\n",
        "def pre_process(text):\n",
        "  words = tokenize(text)\n",
        "  words = [word for word in words if word.isalpha() and word not in stopwords.words('english')]\n",
        "  return(' '.join(words))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FRgms2K7KXXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['processed_text'] = data['text'].apply(pre_process)\n",
        "for i in range(3):  # Adjust the range based on the number of examples you want to print\n",
        "    print(\"Original:\", data['text'][i])\n",
        "    print(\"Preprocessed:\", data['processed_text'][i])\n",
        "    print()"
      ],
      "metadata": {
        "id": "wrgFErbaPsrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "messages = data['processed_text']\n",
        "labels = data[\"spam\"]\n",
        "data['length'] = data['text'].map(lambda text: len(text))\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(messages, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "1APrPTHQnXuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.DataFrame()\n",
        "train_df[\"text\"] = X_train\n",
        "train_df[\"spam\"] = y_train\n",
        "print(\"TRAIN DATA\")\n",
        "print(train_df, \"\\n\\n\\n\")\n",
        "\n",
        "val_df = pd.DataFrame()\n",
        "val_df[\"text\"] = X_val\n",
        "val_df[\"spam\"] = y_val\n",
        "print(\"VALIDATION DATA\")\n",
        "print(val_df, \"\\n\\n\\n\")\n",
        "\n",
        "test_df = pd.DataFrame()\n",
        "test_df[\"text\"] = X_test\n",
        "test_df[\"spam\"] = y_test\n",
        "print(\"TEST DATA\")\n",
        "print(test_df)\n",
        "\n",
        "train_df.to_csv(\"train.csv\", index=False)\n",
        "val_df.to_csv(\"validation.csv\", index=False)\n",
        "test_df.to_csv(\"test.csv\", index=False)"
      ],
      "metadata": {
        "id": "5BM6uRZuneOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"train.csv\")\n",
        "val = pd.read_csv(\"validation.csv\")\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "\n",
        "X_train, y_train = train[\"text\"], train[\"spam\"]\n",
        "X_val, y_val = val[\"text\"], val[\"spam\"]\n",
        "X_test, y_test = test[\"text\"], test[\"spam\"]"
      ],
      "metadata": {
        "id": "cV3kQSo-pHIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "QZ72WAPTglVO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}